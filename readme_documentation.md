# ğŸ¯ Sistema de Captura y DetecciÃ³n Facial con MTCNN

Sistema completo para capturar, detectar, preprocesar y validar datasets de rostros faciales usando MTCNN (Multi-task Cascaded Convolutional Networks).

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Requisitos](#requisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [GuÃ­a de Uso](#guÃ­a-de-uso)
- [ExplicaciÃ³n de Componentes](#explicaciÃ³n-de-componentes)
- [Flujo de Trabajo Recomendado](#flujo-de-trabajo-recomendado)

---

## âœ¨ CaracterÃ­sticas

### âœ… Funcionalidades Principales

- **Captura de Dataset**: Interfaz interactiva para capturar 35-45 fotos por estudiante
- **DetecciÃ³n Facial**: Pipeline completo con MTCNN preentrenado
- **ValidaciÃ³n en Tiempo Real**: VerificaciÃ³n de calidad (rostro detectado, enfoque, iluminaciÃ³n)
- **Sistema de Nombrado AutomÃ¡tico**: Formato `STU001_001.jpg` con timestamps
- **Preprocesamiento Avanzado**: 
  - Redimensionamiento estÃ¡ndar (160x160px)
  - NormalizaciÃ³n de pÃ­xeles
  - EcualizaciÃ³n de histograma (CLAHE)
  - Filtrado de imÃ¡genes borrosas
- **Herramienta de ValidaciÃ³n Visual**: Navegador interactivo con mÃ©tricas de calidad
- **Reportes TÃ©cnicos**: GeneraciÃ³n automÃ¡tica de estadÃ­sticas y anÃ¡lisis

---

## ğŸ“¦ Requisitos

### Software Necesario

- Python 3.8 o superior
- Webcam (para captura en tiempo real)
- 2GB de espacio en disco (para dataset)

### LibrerÃ­as Python

```bash
opencv-python==4.8.1.78
mtcnn==0.1.1
numpy==1.24.3
tensorflow==2.13.0
pillow==10.0.0
matplotlib==3.7.2
```

---

## ğŸš€ InstalaciÃ³n

### Paso 1: Clonar o Descargar Archivos

Crea una carpeta para tu proyecto y coloca todos los archivos:

```bash
mkdir facial-detection-system
cd facial-detection-system
```

### Paso 2: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 3: Verificar InstalaciÃ³n

```bash
python -c "import cv2; import mtcnn; print('âœ“ InstalaciÃ³n exitosa')"
```

---

## ğŸ“ Estructura del Proyecto

```
facial-detection-system/
â”‚
â”œâ”€â”€ capture_dataset.py          # Script de captura de dataset
â”œâ”€â”€ detection_pipeline.py       # Pipeline de detecciÃ³n con MTCNN
â”œâ”€â”€ preprocessing.py            # Sistema de preprocesamiento
â”œâ”€â”€ validation_tool.py          # Herramienta de validaciÃ³n visual
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto
â”œâ”€â”€ README.md                   # Esta documentaciÃ³n
â”‚
â””â”€â”€ dataset/                    # Directorio del dataset (se crea automÃ¡ticamente)
    â”œâ”€â”€ STU001/                 # Carpeta por estudiante
    â”‚   â”œâ”€â”€ STU001_001_20250106_143022.jpg
    â”‚   â”œâ”€â”€ STU001_001_20250106_143022_metadata.json
    â”‚   â”œâ”€â”€ STU001_002_20250106_143025.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ STU002/
    â””â”€â”€ registry.json           # Registro de capturas
```

---

## ğŸ® GuÃ­a de Uso

### 1ï¸âƒ£ Captura de Dataset

**Objetivo**: Capturar 35-45 fotos por estudiante con validaciÃ³n de calidad en tiempo real.

```bash
python capture_dataset.py
```

**Proceso**:

1. Selecciona opciÃ³n `1` para nuevo estudiante
2. Ingresa ID del estudiante (ej: `STU001`)
3. Define nÃºmero de fotos objetivo (default: 40)
4. La cÃ¡mara se abrirÃ¡ mostrando:
   - Bounding box verde/rojo segÃºn calidad
   - 5 landmarks faciales
   - Score de confianza
   - Progreso actual

**Controles**:
- `ESPACIO`: Capturar foto (solo si calidad es OK)
- `Q`: Salir
- `S`: Cambiar de estudiante

**Validaciones AutomÃ¡ticas**:
- âœ… Confianza mÃ­nima: 0.95
- âœ… TamaÃ±o mÃ­nimo del rostro: 100x100px
- âœ… IluminaciÃ³n adecuada (brillo entre 50-200)
- âœ… Rostro detectado y enfocado

**Salida**:
```
dataset/STU001/
  â”œâ”€â”€ STU001_001_20250106_143022.jpg
  â”œâ”€â”€ STU001_001_20250106_143022_metadata.json  # Contiene: timestamp, confidence, box, keypoints
  â”œâ”€â”€ STU001_002_20250106_143025.jpg
  â””â”€â”€ ...
```

---

### 2ï¸âƒ£ Pipeline de DetecciÃ³n

**Objetivo**: Detectar mÃºltiples rostros en imÃ¡genes con MTCNN configurado.

```bash
python detection_pipeline.py
```

**Opciones Disponibles**:

#### A) DetecciÃ³n en Tiempo Real (Webcam)
```
OpciÃ³n 1 â†’ Abre webcam
- Detecta rostros en cada frame
- Muestra bounding boxes y landmarks
- Contador de rostros en tiempo real
- Presiona 'Q' para salir
```

#### B) Procesar Lote de ImÃ¡genes
```
OpciÃ³n 2 â†’ Procesamiento batch
- Ingresa directorio de entrada
- Ingresa directorio de salida
- Genera:
  * ImÃ¡genes anotadas con detecciones
  * Recortes individuales de cada rostro
  * detection_results.json con metadatos
```

**Ejemplo de uso batch**:
```bash
# Desde el script
OpciÃ³n: 2
Directorio de entrada: dataset/STU001
Directorio de salida: processed/STU001

# Salida:
processed/STU001/
  â”œâ”€â”€ annotated_STU001_001.jpg      # Imagen con bounding boxes
  â”œâ”€â”€ detection_results.json         # Metadatos de detecciones
  â””â”€â”€ face_crops/
      â”œâ”€â”€ STU001_001_face1.jpg      # Recorte del rostro
      â””â”€â”€ ...
```

#### C) Procesar Imagen Ãšnica
```
OpciÃ³n 3 â†’ Demo con una imagen
- Muestra detecciones en ventana interactiva
- Ãštil para pruebas rÃ¡pidas
```

**CaracterÃ­sticas del Pipeline**:
- ğŸ” DetecciÃ³n de mÃºltiples rostros por imagen
- ğŸ“Š ExtracciÃ³n de 5 landmarks faciales (ojos, nariz, boca)
- ğŸ“¦ ExtracciÃ³n de bounding boxes con margen ajustable
- ğŸ”„ AlineaciÃ³n facial basada en landmarks de ojos
- âš¡ EstadÃ­sticas de tiempo de procesamiento

---

### 3ï¸âƒ£ Sistema de Preprocesamiento

**Objetivo**: Estandarizar y mejorar calidad del dataset.

```bash
python preprocessing.py
```

**Opciones Disponibles**:

#### A) Preprocesar Dataset Completo
```
OpciÃ³n 1 â†’ Procesa toda la estructura de carpetas
Dataset original: dataset/
Dataset preprocesado: dataset_preprocessed/

# Mantiene la estructura:
dataset_preprocessed/
  â”œâ”€â”€ STU001/
  â”œâ”€â”€ STU002/
  â””â”€â”€ ...
```

#### B) Preprocesar Carpeta Ãšnica
```
OpciÃ³n 2 â†’ Procesa un solo directorio
Entrada: dataset/STU001
Salida: processed/STU001
```

#### C) Demo con Imagen Ãšnica
```
OpciÃ³n 3 â†’ ComparaciÃ³n visual antes/despuÃ©s
- Muestra imagen original y preprocesada lado a lado
```

#### D) Verificar Calidad
```
OpciÃ³n 4 â†’ AnÃ¡lisis de nitidez
- Escanea todas las imÃ¡genes
- Detecta imÃ¡genes borrosas (score Laplaciano < 100)
- Genera reporte de calidad
```

**Pipeline de Preprocesamiento**:

1. **Redimensionamiento EstÃ¡ndar** (160x160px)
   ```python
   # Asegura uniformidad en el dataset
   target_size = (160, 160)
   ```

2. **CLAHE (Contrast Limited Adaptive Histogram Equalization)**
   ```python
   # Mejora contraste localmente
   # Ideal para condiciones de iluminaciÃ³n variable
   ```

3. **NormalizaciÃ³n de PÃ­xeles** [0, 1]
   ```python
   # Opcional: Ãºtil para entrenamiento de modelos
   normalized = image / 255.0
   ```

4. **Filtrado de Calidad**
   - DetecciÃ³n de desenfoque (Laplaciano)
   - ValidaciÃ³n de brillo
   - VerificaciÃ³n de contraste

**Ejemplo de Uso**:
```python
# Preprocesar todo el dataset
preprocessor = FacePreprocessor(target_size=(160, 160))
preprocessor.create_preprocessed_dataset('dataset/', 'dataset_preprocessed/')

# Resultado:
âœ“ STU001: 38/40 imÃ¡genes procesadas (2 rechazadas por desenfoque)
âœ“ STU002: 42/45 imÃ¡genes procesadas (3 rechazadas por desenfoque)
```

---

### 4ï¸âƒ£ Herramienta de ValidaciÃ³n Visual

**Objetivo**: Inspeccionar visualmente el dataset y generar reportes de calidad.

```bash
python validation_tool.py
```

**Opciones Disponibles**:

#### A) Navegador Visual Interactivo
```
OpciÃ³n 1 â†’ Navegar dataset imagen por imagen
```

**Controles del Navegador**:
- `N` o `â†’`: Siguiente imagen
- `P` o `â†`: Imagen anterior  
- `S`: Saltar al siguiente estudiante
- `Q`: Salir

**InformaciÃ³n Mostrada**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Imagen con bounding box y landmarks]â”‚
â”‚                                     â”‚
â”‚ Color del box:                      â”‚
â”‚   ğŸŸ¢ Verde: Confianza â‰¥ 0.99        â”‚
â”‚   ğŸŸ¡ Amarillo: Confianza â‰¥ 0.95     â”‚
â”‚   ğŸ”´ Rojo: Confianza < 0.95         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Panel de InformaciÃ³n:               â”‚
â”‚ â€¢ Estudiante: STU001                â”‚
â”‚ â€¢ Imagen: 15/40                     â”‚
â”‚ â€¢ Score Calidad: 85.0/100           â”‚
â”‚ â€¢ Brillo: 127.3                     â”‚
â”‚ â€¢ Nitidez: 245.7                    â”‚
â”‚ â€¢ Contraste: 52.1                   â”‚
â”‚ â€¢ Issues: [Ninguno]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### B) Generar Reporte de ValidaciÃ³n
```
OpciÃ³n 2 â†’ AnÃ¡lisis automÃ¡tico completo
```

**Genera**: `validation_report.json`

**Contenido del Reporte**:
```json
{
  "timestamp": "2025-01-06T14:30:22",
  "dataset_dir": "dataset/",
  "global_stats": {
    "total_students": 10,
    "total_images": 420,
    "issues_found": 35
  },
  "students": {
    "STU001": {
      "total_images": 40,
      "avg_quality_score": 87.5,
      "avg_confidence": 0.976,
      "images_with_issues": [
        {
          "filename": "STU001_023.jpg",
          "issues": ["Imagen borrosa"],
          "quality_score": 55.0
        }
      ]
    }
  }
}
```

#### C) Revisar Estudiante EspecÃ­fico
```
OpciÃ³n 3 â†’ ValidaciÃ³n de un solo estudiante
ID del estudiante: STU001
```

**MÃ©tricas de Calidad Evaluadas**:

| MÃ©trica | Rango Ã“ptimo | PenalizaciÃ³n |
|---------|--------------|--------------|
| **Brillo** | 50-200 | -20 puntos |
| **Contraste** | â‰¥30 | -15 puntos |
| **Nitidez** | â‰¥100 | -30 puntos |
| **SaturaciÃ³n** | â‰¥20 | -10 puntos |

**Score Final**: 0-100 (100 = calidad perfecta)

---

## ğŸ” ExplicaciÃ³n de Componentes

### ğŸ“¸ 1. capture_dataset.py

**Clase Principal**: `DatasetCapture`

**MÃ©todos Clave**:

```python
def validate_quality(face_data, frame):
    """
    Valida en tiempo real:
    - Confianza de detecciÃ³n â‰¥ 0.95
    - TamaÃ±o mÃ­nimo del rostro
    - IluminaciÃ³n adecuada (brillo promedio)
    
    Returns: (is_valid, message)
    """
```

```python
def capture_for_student(student_id, target_photos=40):
    """
    Loop principal de captura:
    1. Detecta rostro con MTCNN (cada 3 frames)
    2. Valida calidad
    3. Espera tecla ESPACIO para capturar
    4. Guarda imagen + metadata JSON
    5. Actualiza registry.json
    """
```

**Metadata Guardada**:
```json
{
  "timestamp": "20250106_143022_123456",
  "confidence": 0.9876,
  "box": [x, y, width, height],
  "keypoints": {
    "left_eye": [x, y],
    "right_eye": [x, y],
    "nose": [x, y],
    "mouth_left": [x, y],
    "mouth_right": [x, y]
  },
  "resolution": [height, width]
}
```

---

### ğŸ” 2. detection_pipeline.py

**Clase Principal**: `FaceDetectionPipeline`

**ConfiguraciÃ³n de MTCNN**:
```python
detector = MTCNN(
    min_face_size=40,      # TamaÃ±o mÃ­nimo de rostro a detectar
    scale_factor=0.709,    # Factor de escalado de pirÃ¡mide
    steps_threshold=[0.6, 0.7, 0.7]  # Umbrales de las 3 etapas
)
```

**MÃ©todos Importantes**:

```python
def detect_faces(image):
    """
    Detecta rostros y actualiza estadÃ­sticas:
    - Tiempo de procesamiento
    - NÃºmero de rostros detectados
    - Rostros con alta confianza
    
    Returns: Lista de detecciones filtradas por confianza
    """
```

```python
def extract_face_roi(image, box, margin=20):
    """
    Extrae regiÃ³n del rostro con margen:
    - Previene recortes en los bordes
    - Margen configurable
    - Maneja lÃ­mites de imagen
    
    Returns: ROI del rostro
    """
```

```python
def align_face(image, keypoints):
    """
    Alinea rostro basÃ¡ndose en posiciÃ³n de ojos:
    1. Calcula Ã¡ngulo entre ojos
    2. Genera matriz de rotaciÃ³n
    3. Aplica transformaciÃ³n afÃ­n
    
    Returns: Rostro alineado horizontalmente
    """
```

**VisualizaciÃ³n**:
- Bounding boxes con cÃ³digo de colores
- Landmarks con etiquetas (LE, RE, N, ML, MR)
- Scores de confianza
- NumeraciÃ³n de rostros

---

### âš™ï¸ 3. preprocessing.py

**Clase Principal**: `FacePreprocessor`

**Pipeline de Procesamiento**:

```python
def preprocess_pipeline(image):
    """
    Flujo completo:
    1. Redimensionar â†’ 160x160px
    2. CLAHE â†’ Mejorar contraste
    3. Normalizar â†’ [0, 1] (opcional)
    
    Returns: Imagen preprocesada
    """
```

**DetecciÃ³n de Desenfoque**:
```python
def detect_blur(image, threshold=100):
    """
    Usa operador Laplaciano:
    - Calcula varianza del Laplaciano
    - Threshold tÃ­pico: 100
    - < 100 = borrosa, â‰¥ 100 = nÃ­tida
    
    Returns: (is_sharp, variance_score)
    """
```

**CLAHE - ExplicaciÃ³n**:
```
CLAHE (Contrast Limited Adaptive Histogram Equalization)
â”œâ”€â”€ Divide imagen en tiles (8x8)
â”œâ”€â”€ Aplica ecualizaciÃ³n local en cada tile
â”œâ”€â”€ Limita contraste para evitar amplificaciÃ³n de ruido
â””â”€â”€ Interpola bordes entre tiles

Beneficio: Mejora contraste sin sobre-saturar
Ideal para: IluminaciÃ³n no uniforme
```

**AumentaciÃ³n de Datos** (opcional):
```python
augmentation_types = [
    'brightness',  # Ajuste de brillo Â±30%
    'flip',        # Volteo horizontal
    'rotation',    # RotaciÃ³n Â±15Â°
    'noise'        # Ruido gaussiano
]
```

---

### âœ… 4. validation_tool.py

**Clase Principal**: `ValidationTool`

**AnÃ¡lisis de Calidad**:

```python
def analyze_quality_metrics(image):
    """
    Calcula mÃ©tricas completas:
    
    1. Brillo (mean de canal gris)
       - < 50: Muy oscuro
       - > 200: Muy brillante
       - Ã“ptimo: 80-180
    
    2. Contraste (std de canal gris)
       - < 30: Bajo contraste
       - Ã“ptimo: > 40
    
    3. Nitidez (varianza Laplaciano)
       - < 100: Borrosa
       - Ã“ptimo: > 150
    
    4. SaturaciÃ³n (mean de canal S en HSV)
       - < 20: Imagen desaturada
       - Ã“ptimo: > 30
    
    Returns: dict con todas las mÃ©tricas + score final
    """
```

**CÃ¡lculo de Score de Calidad**:
```
Score Inicial: 100 puntos

Penalizaciones:
- Brillo fuera de rango:  -20 puntos
- Bajo contraste:         -15 puntos
- Imagen borrosa:         -30 puntos
- Baja saturaciÃ³n:        -10 puntos

Score Final: max(0, 100 - penalizaciones)
```

**Navegador Interactivo**:
- Muestra imagen con anotaciones de MTCNN
- Panel de informaciÃ³n con mÃ©tricas en tiempo real
- Lista de issues detectados
- NavegaciÃ³n fluida con teclado

---

## ğŸ“Š Flujo de Trabajo Recomendado

### Workflow Completo del Proyecto:

```mermaid
graph TD
    A[Inicio] --> B[1. Captura de Dataset]
    B --> C[capture_dataset.py]
    C --> D[Dataset Crudo: 35-45 fotos/estudiante]
    D --> E[2. DetecciÃ³n y ExtracciÃ³n]
    E --> F[detection_pipeline.py]
    F --> G[Rostros detectados + metadata]
    G --> H[3. Preprocesamiento]
    H --> I[preprocessing.py]
    I --> J[Dataset Preprocesado: 160x160px, CLAHE]
    J --> K[4. ValidaciÃ³n]
    K --> L[validation_tool.py]
    L --> M{Â¿Calidad OK?}
    M -->|SÃ­| N[Dataset Listo]
    M -->|No| O[Re-captura imÃ¡genes con issues]
    O --> B
    N --> P[Entrenamiento de Modelo]
```

### Paso a Paso Detallado:

#### **FASE 1: Captura** (DÃ­as 1-2)
```bash
# 1. Capturar estudiantes
python capture_dataset.py

# Para 10 estudiantes Ã— 40 fotos = 400 imÃ¡genes
# Tiempo estimado: 15-20 min por estudiante
```

#### **FASE 2: DetecciÃ³n** (DÃ­a 3)
```bash
# 2. Procesar dataset completo
python detection_pipeline.py
# OpciÃ³n 2 â†’ Procesar batch
# Input: dataset/
# Output: processed/

# Verifica que todos los rostros se detecten correctamente
```

#### **FASE 3: Preprocesamiento** (DÃ­a 3)
```bash
# 3. Preprocesar imÃ¡genes
python preprocessing.py
# OpciÃ³n 1 â†’ Preprocesar dataset completo
# Input: dataset/
# Output: dataset_preprocessed/

# Filtra imÃ¡genes borrosas automÃ¡ticamente
```

#### **FASE 4: ValidaciÃ³n** (DÃ­a 4)
```bash
# 4. Validar calidad
python validation_tool.py
# OpciÃ³n 2 â†’ Generar reporte

# 5. Revisar visualmente casos con issues
# OpciÃ³n 1 â†’ Navegar dataset

# 6. Re-capturar imÃ¡genes problemÃ¡ticas si es necesario
```

---

## ğŸ“ˆ MÃ©tricas y Entregables

### âœ… Entregables del Proyecto:

1. **ğŸ“ Dataset Parcial Capturado**
   - MÃ­nimo 10 estudiantes Ã— 40 fotos = 400 imÃ¡genes
   - Formato: `STU001_001.jpg` con metadata JSON

2. **ğŸ’» Scripts Funcionales**
   - âœ… `capture_dataset.py`
   - âœ… `detection_pipeline.py`
   - âœ… `preprocessing.py`
   - âœ… `validation_tool.py`

3. **ğŸ“Š Reporte TÃ©cnico**
   ```
   validation_report.json:
   - Tasa de detecciÃ³n exitosa (%)
   - Tiempo promedio de procesamiento por imagen
   - AnÃ¡lisis de casos fallidos (iluminaciÃ³n, pose, distancia)
   ```

4. **ğŸ“¸ EstadÃ­sticas de Calidad**
   - Score promedio de confianza
   - DistribuciÃ³n de scores de calidad
   - IdentificaciÃ³n de mejores/peores capturas

---

## ğŸ¯ Tips y Mejores PrÃ¡cticas

### Para Captura:
1. **IluminaciÃ³n**: Usar luz natural o luz frontal difusa
2. **Fondo**: Preferir fondos uniformes y neutros
3. **Distancia**: Rostro debe ocupar 40-60% del frame
4. **VariaciÃ³n**: Capturar diferentes:
   - Ãngulos de cabeza (Â±15Â°)
   - Expresiones faciales
   - Uso de accesorios (lentes, opcional)

### Para Preprocesamiento:
1. **Threshold de desenfoque**: Ajustar si es muy estricto/permisivo
2. **TamaÃ±o objetivo**: 160x160px es estÃ¡ndar para modelos como FaceNet
3. **CLAHE**: Esencial para dataset con iluminaciÃ³n variable

### Para ValidaciÃ³n:
1. **Revisar primero el reporte JSON**: Identifica estudiantes problemÃ¡ticos
2. **Navegar visualmente**: Verifica casos con score < 70
3. **Re-captura selectiva**: Mejor re-capturar que forzar imÃ¡genes malas

---

## ğŸ› Troubleshooting

### Problema: "No se detecta la webcam"
```python
# Probar diferentes Ã­ndices
cap = cv2.VideoCapture(0)  # Cambiar 0 por 1, 2, etc.
```

### Problema: "MTCNN muy lento"
```python
# Reducir resoluciÃ³n de entrada
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# Procesar cada N frames
if frame_count % 3 == 0:
    faces = detector.detect_faces(frame)
```

### Problema: "Muchas imÃ¡genes rechazadas por desenfoque"
```python
# Ajustar threshold en preprocessing.py
threshold = 100  # Reducir a 80 si es muy estricto
```

---

## ğŸ“š Referencias

- **MTCNN Paper**: Zhang et al. "Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks" (2016)
- **OpenCV Docs**: https://docs.opencv.org/
- **TensorFlow**: https://www.tensorflow.org/

---

## ğŸ‘¨â€ğŸ’» Autor y Soporte

Para dudas o problemas con el sistema, verificar:
1. Versiones de librerÃ­as en `requirements.txt`
2. Permisos de cÃ¡mara en tu sistema operativo
3. Espacio en disco suficiente

**Â¡Ã‰xito con tu proyecto de detecciÃ³n facial! ğŸš€**